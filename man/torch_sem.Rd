% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/torch_sem.R
\name{torch_sem}
\alias{torch_sem}
\title{Structural equation model with a Torch backend}
\usage{
torch_sem(syntax, dtype = torch_float32(), device = torch_device("cpu"))
}
\arguments{
\item{syntax}{lavaan syntax for the SEM model}

\item{dtype}{(optional) torch dtype for the model (default torch_float32())}

\item{device}{(optional) device type to put the model on. see \code{\link[torch:torch_device]{torch::torch_device()}}}
}
\value{
A \code{torch_sem} object, which is an \code{nn_module} (torch object)
}
\description{
Function for creating a structural equation model
}
\details{
This function instantiates a torch object for computing the model-implied covariance matrix
based on a structural equation model. Through \code{torch}, gradients of this forward model can then
be computed using backpropagation, and the parameters can be optimized using gradient-based
optimization routines from the \code{torch} package.

Because of this, it is easy to add additional penalties to the standard objective function,
or to write a new objective function altogether.
}
\section{Fields}{

\describe{
\item{\code{free_params}}{Vector of free parameters}
}}

\section{Methods}{

\subsection{\verb{$initialize()}}{

The initialize method. Don't use this, just use \code{\link[=torch_sem]{torch_sem()}}
\subsection{Arguments}{
\itemize{
\item \code{syntax} lavaan syntax for the SEM model
\item \code{dtype} (optional) torch dtype for the model (default torch_float32())
\item \code{device} (optional) device type to put the model on. see \code{\link[torch:torch_device]{torch::torch_device()}}
}
}

\subsection{Value}{

A \code{torch_sem} object, which is an \code{nn_module} (torch object)
}

}


\subsection{\verb{$forward()}}{

Compute the model-implied covariance matrix.
Don't use this; \code{nn_modules} are callable, so access this method by calling
the object itself as a function, e.g., \code{my_torch_sem()}.
In the forward pass, we apply constraints to the parameter vector, and we
create matrix views from it to compute the model-implied covariance matrix.
\subsection{Value}{

A \code{torch_tensor} of the model-implied covariance matrix
}

}


\subsection{\verb{$inverse_Hessian(loss)}}{

Compute and return the asymptotic covariance matrix of the parameters with
respect to the loss function
\subsection{Arguments}{
\itemize{
\item \code{loss} torch_tensor of freshly computed loss function (needed by torch
for backwards pass)
}
}

\subsection{Value}{

A \code{torch_tensor}, representing the ACOV of the free parameters
}

}


\subsection{\verb{$standard_errors(loss)}}{

Compute and return observed information standard errors of the
parameters, assuming the loss function is the likelihood and the
current estimates are ML estimates.
\subsection{Arguments}{
\itemize{
\item \code{loss} torch_tensor of freshly computed loss function (needed by torch
for backwards pass)
}
}

\subsection{Value}{

A \verb{numeric vector} of standard errors of the free parameters
}

}


\subsection{\verb{$partable(loss)}}{

Create a lavaan-like parameter table from the current parameter estimates in the
torch_sem object.
\subsection{Arguments}{
\itemize{
\item \code{loss} (optional) torch_tensor of freshly computed loss function (needed by torch
for backwards pass)
}
}

\subsection{Value}{

lavaan partable object
}

}


\subsection{\verb{$fit(dat, lrate, maxit, verbose, tol)}}{

Fit a torch_sem model using the default maximum likelihood objective.
This function uses the Adam optimizer to estimate the parameters of a torch_sem
\subsection{Arguments}{
\itemize{
\item \code{dat} dataset (centered!) as a \code{torch_tensor}
\item \code{lrate} learning rate of the Adam optimizer.
\item \code{maxit} maximum number of epochs to train the model
\item \code{verbose} whether to print progress to the console
\item \code{tol} parameter change tolerance for stopping training
}
}

\subsection{Value}{

Self, i.e., the \code{torch_sem} object with updated parameters
}

}


\subsection{\verb{$loglik(dat)}}{

Multivariate normal log-likelihood of the data.
\subsection{Arguments}{
\itemize{
\item \code{dat} dataset (centered!) as a \code{torch_tensor}
}
}

\subsection{Value}{

Log-likelihood value (torch scalar)
}

}
}

