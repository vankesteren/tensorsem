% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/torch_sem.R
\name{torch_sem}
\alias{torch_sem}
\alias{sem_Module}
\title{Structural equation model with a Torch backend}
\usage{
torch_sem(syntax, dtype = torch_float32(), device = torch_device("cpu"))
}
\arguments{
\item{syntax}{lavaan syntax for the SEM model}

\item{dtype}{(optional) torch dtype for the model (default torch_float32())}

\item{device}{(optional) device type to put the model on. see \code{\link[torch:torch_device]{torch::torch_device()}}}
}
\value{
A \code{torch_sem} object, which is an \code{nn_module} (torch object)
}
\description{
Function for creating a structural equation model
}
\details{
This function instantiates a torch object for computing the model-implied covariance matrix
based on a structural equation model. Through \code{torch}, gradients of this forward model can then
be computed using backpropagation, and the parameters can be optimized using gradient-based
optimization routines from the \code{torch} package.

Because of this, it is easy to add additional penalties to the standard objective function,
or to write a new objective function altogether.
}
\section{Super class}{
\code{torch::nn_Module} -> \code{torch_sem}
}
\section{Public fields}{
\if{html}{\out{<div class="r6-fields">}}
\describe{
\item{\code{.classes}}{(for compatibility with torch package)}
}
\if{html}{\out{</div>}}
}
\section{Active bindings}{
\if{html}{\out{<div class="r6-active-bindings">}}
\describe{
\item{\code{free_params}}{Vector of free parameters}
}
\if{html}{\out{</div>}}
}
\section{Methods}{
\subsection{Public methods}{
\itemize{
\item \href{#method-torch_sem-new}{\code{sem_Module$new()}}
\item \href{#method-torch_sem-forward}{\code{sem_Module$forward()}}
\item \href{#method-torch_sem-inverse_Hessian}{\code{sem_Module$inverse_Hessian()}}
\item \href{#method-torch_sem-standard_errors}{\code{sem_Module$standard_errors()}}
\item \href{#method-torch_sem-partable}{\code{sem_Module$partable()}}
\item \href{#method-torch_sem-fit}{\code{sem_Module$fit()}}
\item \href{#method-torch_sem-loglik}{\code{sem_Module$loglik()}}
\item \href{#method-torch_sem-clone}{\code{sem_Module$clone()}}
}
}
\if{html}{\out{
<details><summary>Inherited methods</summary>
<ul>
<li><span class="pkg-link" data-pkg="torch" data-topic="nn_Module" data-id=".apply"><a href='../../torch/html/nn_Module.html#method-nn_Module-.apply'><code>torch::nn_Module$.apply()</code></a></span></li>
<li><span class="pkg-link" data-pkg="torch" data-topic="nn_Module" data-id=".load_from_state_dict"><a href='../../torch/html/nn_Module.html#method-nn_Module-.load_from_state_dict'><code>torch::nn_Module$.load_from_state_dict()</code></a></span></li>
<li><span class="pkg-link" data-pkg="torch" data-topic="nn_Module" data-id=".save_to_state_dict"><a href='../../torch/html/nn_Module.html#method-nn_Module-.save_to_state_dict'><code>torch::nn_Module$.save_to_state_dict()</code></a></span></li>
<li><span class="pkg-link" data-pkg="torch" data-topic="nn_Module" data-id="add_module"><a href='../../torch/html/nn_Module.html#method-nn_Module-add_module'><code>torch::nn_Module$add_module()</code></a></span></li>
<li><span class="pkg-link" data-pkg="torch" data-topic="nn_Module" data-id="apply"><a href='../../torch/html/nn_Module.html#method-nn_Module-apply'><code>torch::nn_Module$apply()</code></a></span></li>
<li><span class="pkg-link" data-pkg="torch" data-topic="nn_Module" data-id="cpu"><a href='../../torch/html/nn_Module.html#method-nn_Module-cpu'><code>torch::nn_Module$cpu()</code></a></span></li>
<li><span class="pkg-link" data-pkg="torch" data-topic="nn_Module" data-id="cuda"><a href='../../torch/html/nn_Module.html#method-nn_Module-cuda'><code>torch::nn_Module$cuda()</code></a></span></li>
<li><span class="pkg-link" data-pkg="torch" data-topic="nn_Module" data-id="eval"><a href='../../torch/html/nn_Module.html#method-nn_Module-eval'><code>torch::nn_Module$eval()</code></a></span></li>
<li><span class="pkg-link" data-pkg="torch" data-topic="nn_Module" data-id="load_state_dict"><a href='../../torch/html/nn_Module.html#method-nn_Module-load_state_dict'><code>torch::nn_Module$load_state_dict()</code></a></span></li>
<li><span class="pkg-link" data-pkg="torch" data-topic="nn_Module" data-id="named_buffers"><a href='../../torch/html/nn_Module.html#method-nn_Module-named_buffers'><code>torch::nn_Module$named_buffers()</code></a></span></li>
<li><span class="pkg-link" data-pkg="torch" data-topic="nn_Module" data-id="named_parameters"><a href='../../torch/html/nn_Module.html#method-nn_Module-named_parameters'><code>torch::nn_Module$named_parameters()</code></a></span></li>
<li><span class="pkg-link" data-pkg="torch" data-topic="nn_Module" data-id="print"><a href='../../torch/html/nn_Module.html#method-nn_Module-print'><code>torch::nn_Module$print()</code></a></span></li>
<li><span class="pkg-link" data-pkg="torch" data-topic="nn_Module" data-id="register_buffer"><a href='../../torch/html/nn_Module.html#method-nn_Module-register_buffer'><code>torch::nn_Module$register_buffer()</code></a></span></li>
<li><span class="pkg-link" data-pkg="torch" data-topic="nn_Module" data-id="register_module"><a href='../../torch/html/nn_Module.html#method-nn_Module-register_module'><code>torch::nn_Module$register_module()</code></a></span></li>
<li><span class="pkg-link" data-pkg="torch" data-topic="nn_Module" data-id="register_parameter"><a href='../../torch/html/nn_Module.html#method-nn_Module-register_parameter'><code>torch::nn_Module$register_parameter()</code></a></span></li>
<li><span class="pkg-link" data-pkg="torch" data-topic="nn_Module" data-id="state_dict"><a href='../../torch/html/nn_Module.html#method-nn_Module-state_dict'><code>torch::nn_Module$state_dict()</code></a></span></li>
<li><span class="pkg-link" data-pkg="torch" data-topic="nn_Module" data-id="to"><a href='../../torch/html/nn_Module.html#method-nn_Module-to'><code>torch::nn_Module$to()</code></a></span></li>
<li><span class="pkg-link" data-pkg="torch" data-topic="nn_Module" data-id="train"><a href='../../torch/html/nn_Module.html#method-nn_Module-train'><code>torch::nn_Module$train()</code></a></span></li>
<li><span class="pkg-link" data-pkg="torch" data-topic="nn_Module" data-id="zero_grad"><a href='../../torch/html/nn_Module.html#method-nn_Module-zero_grad'><code>torch::nn_Module$zero_grad()</code></a></span></li>
</ul>
</details>
}}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-torch_sem-new"></a>}}
\if{latex}{\out{\hypertarget{method-torch_sem-new}{}}}
\subsection{Method \code{new()}}{
The initialize method. Don't use this, just use \code{\link[=torch_sem]{torch_sem()}}
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{sem_Module$new(syntax, dtype = torch_float32(), device = torch_device("cpu"))}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{syntax}}{lavaan syntax for the SEM model}

\item{\code{dtype}}{(optional) torch dtype for the model (default torch_float32())}

\item{\code{device}}{(optional) device type to put the model on. see \code{\link[torch:torch_device]{torch::torch_device()}}}
}
\if{html}{\out{</div>}}
}
\subsection{Returns}{
A \code{torch_sem} object, which is an \code{nn_module} (torch object)
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-torch_sem-forward"></a>}}
\if{latex}{\out{\hypertarget{method-torch_sem-forward}{}}}
\subsection{Method \code{forward()}}{
Compute the model-implied covariance matrix.
In the forward pass, we apply constraints to the parameter vector, and we
create matrix views from it to compute the model-implied covariance matrix.
Also accessible by calling the object itself as a function, e.g., \code{my_torch_sem()}.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{sem_Module$forward()}\if{html}{\out{</div>}}
}

\subsection{Returns}{
\code{torch_tensor} model-implied covariance matrix
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-torch_sem-inverse_Hessian"></a>}}
\if{latex}{\out{\hypertarget{method-torch_sem-inverse_Hessian}{}}}
\subsection{Method \code{inverse_Hessian()}}{
Compute and return the asymptotic covariance matrix of the parameters with
respect to the loss function, to compute standard errors \emph{(sqrt(diag(ACOV)))}
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{sem_Module$inverse_Hessian(loss)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{loss}}{freshly computed loss function (for backwards pass)}
}
\if{html}{\out{</div>}}
}
\subsection{Returns}{
\code{torch_tensor} ACOV of the free parameters
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-torch_sem-standard_errors"></a>}}
\if{latex}{\out{\hypertarget{method-torch_sem-standard_errors}{}}}
\subsection{Method \code{standard_errors()}}{
Compute and return observed information standard errors of the parameters, assuming
the loss function is the likelihood and the current estimates are ML estimates.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{sem_Module$standard_errors(loss)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{loss}}{freshly computed loss function (needed by torch for backwards pass)}
}
\if{html}{\out{</div>}}
}
\subsection{Returns}{
\code{vector} standard errors of the free parameters
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-torch_sem-partable"></a>}}
\if{latex}{\out{\hypertarget{method-torch_sem-partable}{}}}
\subsection{Method \code{partable()}}{
Create a lavaan-like parameter table from the current parameter estimates in the
torch_sem object.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{sem_Module$partable(loss)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{loss}}{(optional) freshly computed loss function to obtain standard errors.}
}
\if{html}{\out{</div>}}
}
\subsection{Returns}{
lavaan partable object
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-torch_sem-fit"></a>}}
\if{latex}{\out{\hypertarget{method-torch_sem-fit}{}}}
\subsection{Method \code{fit()}}{
Fit a torch_sem model using the default maximum likelihood objective.
This function uses the Adam optimizer to estimate the parameters of a torch_sem
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{sem_Module$fit(dat, lrate = 0.01, maxit = 5000, verbose = TRUE, tol = 1e-20)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{dat}}{dataset (centered!) as a \code{torch_tensor}}

\item{\code{lrate}}{learning rate of the Adam optimizer.}

\item{\code{maxit}}{maximum number of epochs to train the model}

\item{\code{verbose}}{whether to print progress to the console}

\item{\code{tol}}{parameter change tolerance for stopping training}
}
\if{html}{\out{</div>}}
}
\subsection{Returns}{
self
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-torch_sem-loglik"></a>}}
\if{latex}{\out{\hypertarget{method-torch_sem-loglik}{}}}
\subsection{Method \code{loglik()}}{
Multivariate normal log-likelihood of the data.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{sem_Module$loglik(dat)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{dat}}{torch tensor data}
}
\if{html}{\out{</div>}}
}
\subsection{Returns}{
log-likelihood value (torch scalar)
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-torch_sem-clone"></a>}}
\if{latex}{\out{\hypertarget{method-torch_sem-clone}{}}}
\subsection{Method \code{clone()}}{
The objects of this class are cloneable with this method.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{sem_Module$clone(deep = FALSE)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{deep}}{Whether to make a deep clone.}
}
\if{html}{\out{</div>}}
}
}
}
